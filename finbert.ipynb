{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d9a8d25992e49e68b8335cb9824aa22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_542be3b7287548aebd60471e36d156d4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b144b7042394405abca032866515855d",
              "IPY_MODEL_8795d51a69c94a548dd5d60d42e4ba3e"
            ]
          }
        },
        "542be3b7287548aebd60471e36d156d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b144b7042394405abca032866515855d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76783ef48adc44ada9f86450327e73fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b58549e0a954444abf6faa384a056fe"
          }
        },
        "8795d51a69c94a548dd5d60d42e4ba3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa483aa7a77f4ef8bf987225402f0423",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/? [00:00&lt;00:00,  9.88 tables/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3a2d8b481024c92b617cfe1408e367f"
          }
        },
        "76783ef48adc44ada9f86450327e73fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b58549e0a954444abf6faa384a056fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa483aa7a77f4ef8bf987225402f0423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3a2d8b481024c92b617cfe1408e367f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9h8sIUIxA9Y",
        "outputId": "95cb7e1c-8592-4a1f-c73d-c5e1e8ee54d4"
      },
      "source": [
        "pip install -r requirements.txt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.18.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.22)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: PILLOW in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.0.1)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (3.5)\n",
            "Requirement already satisfied: transformers==4.3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (4.3.3)\n",
            "Requirement already satisfied: datasets==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (1.4.1)\n",
            "Requirement already satisfied: bertviz==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (1.0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.32.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 5)) (7.6.3)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 5)) (5.0.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 5)) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 5)) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 5)) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->-r requirements.txt (line 11)) (5.1.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->-r requirements.txt (line 11)) (20.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->-r requirements.txt (line 11)) (0.16.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->-r requirements.txt (line 11)) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->-r requirements.txt (line 11)) (0.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->-r requirements.txt (line 11)) (4.41.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->-r requirements.txt (line 11)) (0.29.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->-r requirements.txt (line 11)) (0.1.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 13)) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 13)) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 15)) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 15)) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 15)) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 15)) (3.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 15)) (0.0.44)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.4.1->-r requirements.txt (line 16)) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.2 in /usr/local/lib/python3.7/dist-packages (from datasets==1.4.1->-r requirements.txt (line 16)) (0.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets==1.4.1->-r requirements.txt (line 16)) (2021.4.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.4.1->-r requirements.txt (line 16)) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.4.1->-r requirements.txt (line 16)) (0.70.11.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from bertviz==1.0.0->-r requirements.txt (line 18)) (1.17.53)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from bertviz==1.0.0->-r requirements.txt (line 18)) (0.1.95)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from bertviz==1.0.0->-r requirements.txt (line 18)) (1.8.1+cu101)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow->-r requirements.txt (line 4)) (54.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (1.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (3.3.4)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 5)) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 5)) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 5)) (3.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 5)) (5.0.5)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 5)) (1.9.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 5)) (4.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 5)) (22.0.3)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 5)) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 5)) (5.1.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 5)) (0.9.4)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 5)) (2.11.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 5)) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 5)) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 5)) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 5)) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 5)) (1.0.18)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->-r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->-r requirements.txt (line 11)) (2020.12.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->-r requirements.txt (line 11)) (1.53.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.53 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz==1.0.0->-r requirements.txt (line 18)) (1.20.53)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz==1.0.0->-r requirements.txt (line 18)) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz==1.0.0->-r requirements.txt (line 18)) (0.3.7)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r requirements.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r requirements.txt (line 5)) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r requirements.txt (line 5)) (4.8.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 5)) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->-r requirements.txt (line 5)) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 5)) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->-r requirements.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->-r requirements.txt (line 4)) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di60ZuNPzfm0",
        "outputId": "137dc349-1eba-4faa-c50f-2c1591bb5b6d"
      },
      "source": [
        "!pip install bertviz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bertviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/8b/f4226c75b35df80504ef41399fc1569b550332e3e4796618e5669c91af55/bertviz-1.0.0-py3-none-any.whl (162kB)\n",
            "\r\u001b[K     |██                              | 10kB 24.2MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61kB 19.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 81kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 92kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 102kB 18.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 112kB 18.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 122kB 18.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 133kB 18.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 143kB 18.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 153kB 18.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 18.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bertviz) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.5.1)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (1.8.1+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from bertviz) (2019.12.20)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/b3/8c889dd3d5ae47a9c4468cc20ef980adc4a16f06f0937ab33f78b58b5eda/boto3-1.17.53-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 60.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2020.12.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (3.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.0.44)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->bertviz) (3.7.4.3)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/89/0cb4e92c239e6425b9b0035227b8cdf9d3d098a5c9e95632c3815df63a09/s3transfer-0.3.7-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.5MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.53\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/4e/232e261b739534e216f28d935a06c44840221c3476ebcdb411cd0fc2bf16/botocore-1.20.53-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 56.1MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.0->bertviz) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=2.0->bertviz) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.0->bertviz) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.0->bertviz) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.0->bertviz) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.53->boto3->bertviz) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.53 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, jmespath, botocore, s3transfer, boto3, bertviz\n",
            "Successfully installed bertviz-1.0.0 boto3-1.17.53 botocore-1.20.53 jmespath-0.10.0 s3transfer-0.3.7 sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyKey9OyzXfD",
        "outputId": "f0f4bb29-ddef-40ec-cb2c-bcc96a4aa01b"
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# Data related\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "from transformers.trainer_utils import set_seed\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
        "from transformers import TFBertForSequenceClassification\n",
        "from transformers import TFBertForMaskedLM\n",
        "from transformers.data.data_collator import DataCollatorForLanguageModeling\n",
        "from transformers.modeling_tf_utils import TFMaskedLanguageModelingLoss\n",
        "\n",
        "from bertviz import head_view\n",
        "from collections import Counter\n",
        "\n",
        "# TF 2.4\n",
        "# Cuda 11.0\n",
        "# CuDNN 8.0.5 (CUDA 11.0)\n",
        "# at nvidia-smi if you encounter Failed to initialize NVML: Driver/library version mismatch\n",
        "# simply restart the computer and see if it goes away\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import torch\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "random_seed=4321\n",
        "\n",
        "set_seed(random_seed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89,
          "referenced_widgets": [
            "9d9a8d25992e49e68b8335cb9824aa22",
            "542be3b7287548aebd60471e36d156d4",
            "b144b7042394405abca032866515855d",
            "8795d51a69c94a548dd5d60d42e4ba3e",
            "76783ef48adc44ada9f86450327e73fb",
            "7b58549e0a954444abf6faa384a056fe",
            "aa483aa7a77f4ef8bf987225402f0423",
            "b3a2d8b481024c92b617cfe1408e367f"
          ]
        },
        "id": "4jKKtEx9zdmR",
        "outputId": "8691de34-0a86-408e-a79b-53aa551a8323"
      },
      "source": [
        "dataset = load_dataset('csv', data_files='240min_Amazon_news_direction_updated.csv')"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-cc3504bc683bd43a\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-cc3504bc683bd43a/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d9a8d25992e49e68b8335cb9824aa22",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-cc3504bc683bd43a/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuzbqpM61GUB",
        "outputId": "9c662cfe-428d-4bf0-f603-c2b64f1ffba2"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['news', 'direction'],\n",
            "        num_rows: 2032\n",
            "    })\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev382y1S1Ll4",
        "outputId": "9ba5c939-56ef-4144-e953-f88f46c7de5f"
      },
      "source": [
        "for s,l in zip(dataset['train']['news'][:10], dataset['train']['direction'][:10]):\n",
        "    print(s)\n",
        "    print('\\tLabel: {}'.format(l))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "andr januari nasdaq surg big name tech stock continu show dominance. well fang stock perform could room run scorecard facebook fb amazon amzn netflix nflx googl parent alphabet googl appl aapl . facebook x facebook gain . stock last broke base octob seen somewhat sluggish sideway action sinc then. facebook share remain within buy rang . entri lost support key day line. facebook also new flat base . buy point. investor may want focus entri now. amazon amazon share increas stock could soon present fresh buy opportunity. friday close stock complet five week base build minimum amount time take base form. new buy point . . late stage base mean higher odd failing. ibd take look high qualiti stock potenti big gain make sure check leaderboard curat list top growth name near potenti buy points. new ibd take free trial leaderboard. netflix netflix rose year built sever base along run. share close friday back day line tri build right side base . entry. alphabet googl parent alphabet climb least fang peer year. hit time high . dec. share steadili slip push stock back buy range. last entri point alphabet . . appl appl gain year. appl recent breakout . flat base buy point met resist share lost support day line friday. declin could trigger sell signal convinc support day line would posit indicator. might interest stock buy watch top ipo big small cap growth stock dow jone industri averag dow stock news analysi fang stock news quot facebook amazon netflix googl\n",
            "\tLabel: 1\n",
            "happen share mani optic network specialist plung decemb accord data p global market intellig . lumentum hold nasdaq lite end month . lower infinera nasdaq infn investor took . hit appli optoelectron nasdaq aaoi fell . . mani other saw smaller price reduct industri biggest loser december. imag sourc getti images. sectorwid plung start negat analyst note appli optoelectronics. maker fiber optic network compon laser transceiv major supplier network tool amazon.com nasdaq amzn analyst firm cowen co. fear amazon move newer faster transceiv hurt compani short term. share price fell cautious report drag appli optoelectron peer along smaller price drops. later finisar nasdaq fnsr broke slump appl nasdaq aapl invest million compani laser research. laser play import part iphon x face scan featur make finisar essenti cupertino partner. finisar share surg much higher day though gain fade finisar share close decemb . higher. fellow laser builder infinera appli optoelectron fell news sinc appl seem like reach altern laser supplier move like that. throughout month analyst kept repeat mantra chines network invest pick back tough year slowly. even larg lumentum order china telecom nyse cha lift lumentum share coupl percent. amazon generat shift network issu soft chines growth prospect fiber optic network market whole oper dark clouds. decemb fiber optic worri real enough. still long term view industri remain strong. telecom data network around world speed take bandwidth. even wireless improv inevit lead upgrad fiber optic infrastructur connect cell tower internet large. know cloud comput run hot cloud specialist like amazon drive signific portion world optic network compon needs. thing run bit slow moment. regulatori uncertainti play larg part china america. standard bodi put finish touch g wireless technolog among thing hidden groundswel upcom hardwar need quit readi met yet. three last month biggest dip tie high qualiti businesses. among appli optoelectron seem offer biggest opportun strong bounc lumentum infinera provid stability. look like solid buy bargain price earli . stock like better infinera invest genius david tom gardner stock tip pay listen. newslett run decad motley fool stock advisor tripl market. david tom reveal believ best stock investor buy right now... infinera one right think stock even better buys. click learn pick stock advisor return januari john mackey ceo whole food market amazon subsidiari member motley fool board directors. ander bylund own share amazon. motley fool own share recommend amazon appl infinera. motley fool follow option long januari call appl short januari call apple. motley fool disclosur polici .\n",
            "\tLabel: 1\n",
            "happen share mani optic network specialist plung decemb accord data p global market intellig . lumentum hold nasdaq lite end month . lower infinera nasdaq infn investor took . hit appli optoelectron nasdaq aaoi fell . . mani other saw smaller price reduct industri biggest loser december. sectorwid plung start negat analyst note appli optoelectronics. maker fiber optic network compon laser transceiv major supplier network tool amazon.com nasdaq amzn analyst firm cowen co. fear amazon move newer faster transceiv hurt compani short term. share price fell cautious report drag appli optoelectron peer along smaller price drops. later finisar nasdaq fnsr broke slump appl nasdaq aapl invest million compani laser research. laser play import part iphon x face scan featur make finisar essenti cupertino partner. finisar share surg much higher day though gain fade finisar share close decemb . higher. fellow laser builder infinera appli optoelectron fell news sinc appl seem like reach altern laser supplier move like that. throughout month analyst kept repeat mantra chines network invest pick back tough year slowly. even larg lumentum order china telecom nyse cha lift lumentum share coupl percent. amazon generat shift network issu soft chines growth prospect fiber optic network market whole oper dark clouds. decemb fiber optic worri real enough. still long term view industri remain strong. telecom data network around world speed take bandwidth. even wireless improv inevit lead upgrad fiber optic infrastructur connect cell tower internet large. know cloud comput run hot cloud specialist like amazon drive signific portion world optic network compon needs. thing run bit slow moment. regulatori uncertainti play larg part china america. standard bodi put finish touch g wireless technolog among thing hidden groundswel upcom hardwar need quit readi met yet. three last month biggest dip tie high qualiti businesses. among appli optoelectron seem offer biggest opportun strong bounc lumentum infinera provid stability. look like solid buy bargain price earli .\n",
            "\tLabel: 1\n",
            "shutterstock photo stock index open new year first session cheer note major index grip solid gain midday tuesday. ibd display video id width float left autostart true nasdaq pop . p dow jone industri averag advanc . . respectively. small cap russel one point ad . . volum stock market today run far friday pace. philadelphia semiconductor index . gain energ nasdaq. sox tri regain day line high. fang stock facebook fb amazon.com amzn netflix nflx alphabet googl also well. netflix show best gain heavi volume. analyst citi said likelihood appl aapl buy netflix. appl expect repatri billion cash new tax laws. citi analyst said appl enough cash buy netflix. meanwhil macquari research upgrad netflix neutral outperform lift price target . appl sometim includ fang group rose . fast trade midday tuesday. among ibd industri group depart store steel produc among day upsid leaders. downsid meat alcohol beverag sagged. innov ibd fund ffti rose . . exchang trade fund reflect ibd list strongest stock via fundament technicals. innov fund advanc . . relat tell stock live danger stock index repeat winner\n",
            "\tLabel: 1\n",
            ". . . submarin trend tech world affect near everi compani know amzn aapl fb nflx googl seth archer us navi artifici intellig took world storm impact tech world hard measure. technolog woven everyth modern tech compani show profit loss statement example. one biggest tech trend year also one hardest quantify. artifici intellig start creep almost present product announc busi plan silicon valley last month good reason. artifici intellig work solv lot problem previous impossible. ai one submarin trend mark mahaney analyst rbc told market insider. impact tide surfac hard see it. even though larg number compani start work ai technolog impact bottom line almost imposs see. googl good example. near everi flagship phone releas year use two camera lens creat blurri background photos. googl use singl len pixel phone reli ai softwar blur background photos. even though ai enabl core featur one compani flagship product hard attribut direct impact ai system sale phone. compani ai impact even less obvious. netflix use ai deciph user prefer present interest content base key indicators. seem work compani subscrib count continu increas cost develop recommend engin broken compani financi statement hard predict good ai less recommend engin could be. hard see impact financi perspect hard find line p l say artifici intellig term expens mahaney said. form relev effect services. perhap best way quantifi ai impact tech world look much spent research develop top tech companies. tech compani outperform general market wide margin mahaney said huge invest tech compani make develop new technolog one biggest reason continu earn stock price growth. ve... struck consist aggress invest companies. compani spend aggress new area growth mahaney said. high level invest ai technolog like continu mahaney say good indic compani futur performance. thing could realli stop tech compani next year general rotat tech area mahaney said. know famous last word consist last three years.\n",
            "\tLabel: 1\n",
            "california pot shop ring ring first legal sale associ press min ago brian melley terenc chea click expand replay video next california marijuana market reach near billion januari state california set begin sale recreat marijuana market expect reach . billion alone. research firm bds analyt add report number increas billion year after. bds goe say california world sixth largest economi huge chunk total north america market cannabis. wochit news trump target amazon call postal servic hike price presid donald trump goe amazon twitter say u.s. postal servic rais price stop internet retail profit expense. ashraf fahim reports. reuter america guy fieri time squar restaur close guy american kitchen amp bar famous pan new york time open . cbs news cancel set hd hq sd lo new year bring broad pot legal calif. associ press see video share share tweet share email watch next california marijuana market reach near billion wochit news trump target amazon call postal servic hike price reuter america guy fieri time squar restaur close cbs news win lotteri cbs news secret bitcoin millionair give away million chariti cnbc goldman sach expect lose billion gop tax reform bill fox busi clair test makeup product asbesto newsi trump organ deni report trump definit still involv busi veuer appl tri appeas old iphon user discount batteri wochit tech last minut charit deduct tip street disney hotel get rid disturb sign veuer state live affect chanc win powerbal cbs news bitcoin could myspac cryptocurr gobankingr recreat weed calif. might hard come jan. cbs news uber billion valuat drop billion wochit busi concern china economi surpass us overblown fox busi next oakland calif. custom line earli purchas recreat marijuana legal first time california new year brought broad legal two decad state first allow pot medic use. popular search appl inc aapl v . . . salesforce.com inc crm v . . . microsoft corp msft v . . . barrick gold corp abx . . . jeff deakin wife mari dog wait night first line peopl harborsid dispensari longtim medic pot shop oakland open a.m. offer earli custom joint penni free shirt read flower peopl cannabi all. long sinc other could walk place could feel safe secur abl get someth good without go back alley deakin said. kind big deal everybody. nation popul state join grow list state nation capit call recreat marijuana permit even though feder govern continu classifi pot control substanc like heroin lsd. california voter made legal adult older grow possess use limit quantiti marijuana legal sell recreat purpos monday. find retail outlet buy non medic pot california easi least initially. busi receiv state licens open new year day. concentr san diego santa cruz san francisco bay area palm spring area. los angel san francisco among mani citi recreat pot avail right away local regul approv time start issu citi licens need get state permits. meanwhil fresno bakersfield riversid among communiti adopt law forbid recreat marijuana sales. midnight rais joint instead champagn glasses. johnni hernandez tattoo artist modesto celebr smoke happi new year blunt cousins. someth wait said. peopl might actual realiz weed bad. help lot people. berkeley mayor jess arreguin state sen. nanci skinner hand ribbon cut ceremoni citi began sell marijuana legally. custom began line dawn monday outsid berkeley patient group one oldest dispensari nation. c associ press margot simpson right diana gladden wait line purchas marijuana harborsid marijuana dispensari monday jan. oakland calif. start new year day recreat marijuana sold legal california. ap photo mathew sumner los angel offici announc late last month citi begin accept licens applic jan. might take week licens issued. led widespread concern long establish busi would shut interim. howev attorney advis group citi dispensari conclud busi continu legal sell medicin marijuana collect obtain local state licens new system said jer kiloh unit cannabi busi associ industri group. immedi clear mani shop would open new year day. tri continu provid patient access said kiloh own dispensari citi san fernando valley area. new licens system stall los angel patient scare employe scared. status los angel shop highlight broad confus new law. state regul said shop must local state licens open busi new year. citi top pot regul cat packer told report last month medicin sale continu consum doctor recommend new licens issued. state ban loco weed accord histori nation organ reform marijuana law pot advocaci group known norml. first attempt undo voter initi fail three year later feloni possess less ounc downgrad misdemeanor. object law e\n",
            "\tLabel: 1\n",
            "tuesday vital data micron general electr amazon read break news sponsor jan est januari stellar earn visibl keep appl aapl strong buy aapl stock strong buy latest week rating. get aapl alert submit portfolio grader current rank appl inc nasdaq aapl strong buy. use loui navelli invest methodolog analyt tool research stock employ proprietari fundament quantit analyt tools. repres chang previous week rank aapl portfolio grader months. compani classifi member compani technolog hardwar storag peripher gic industri group segment compani gic inform technolog sector. aapl market valu . billion fall top decil industri group stock current portfolio grader score place among compani industri group put top decile. portfolio grader current rank inform technolog sector number among sector univers put top half gic sectors. technolog hardwar storag peripher industri group rank among industri group within gic sector place well averag term navelli score system. appl earn averag score fundament area apprais portfolio grader rank compani stocks. aapl oper score sourc strength rank sale growth oper margin earn growth discern average. score visibl earn superior rank earn revis earn surpris earn momentum discern better average. aapl rank return equiti mark better industri group averag grade cash flow average. base fundament score appl place top quartil industri group. portfolio grader use navelli proprietari quantit score measur aapl share perspect risk reward. uniqu score system consid relat valu compani share base current price share relat peer market risk associ industri sector groups. use risk reward calcul aapl current score well averag industri group compar peers. loui navelli proprietari portfolio grader stock rank system assess rough compani everi week base number fundament quantit measures. stock given letter grade base result strong buy f strong sell . explor tool .\n",
            "\tLabel: 1\n",
            "aapl tmus twx vz inc. nyse fire ralli sinc novemb . howev stock price still far . time get recent momentum take pass telecom giant let look chart first. trade stock pri aapl hyg jnk slx u.s. equiti melt higher monday push dow jone industri averag th record close year someth never done price momentum push overbought level sinc s. month sinc presid trump amazon look squash appl homepod amazon.com inc. nasdaq amzn biggest holiday season ever year best sell product echo dot voic control speaker fire tv stick sold . . respectively. appl inc. nasdaq aapl delay launch homepod voic control speaker sometim january. even avail chanc homepod would far behind echo dot sale due main devic pricing. amazon let pressure. e commerc leviathan continu sell echo dot . discount list price . even holiday season reced rear view mirror. smart speaker like amazon echo echo dot appl homepod alphabet inc. nasdaq googl googl home reach critic adopt threshold accord comscore. analyst emarket project number u.s. smart speaker user reach . million internet user . million . internet user . day christma emarket analyst cindi liu compar consum interest smart speaker interest wearabl like appl watch consum yet find reason justifi cost smartwatch sometim cost much smartphone. instead holiday season expect smart speaker gift choic mani tech enthusiast lower price points. given amazon consist strategi strive share profit easi see compani keep price echo dot low. smart speaker posit gateway devic smart home varieti smart applianc smart devic like thermostat light voic control smart speaker. amazon unquest leader voic control devic plan build leadership posit keep appl also ran. googl home sell walmart promot discount custom buy one googl express put even pressur apple. look like appl catch smart speaker wave right time compani go swamp result. also read top retail noth fear amazon\n",
            "\tLabel: 1\n",
            "spotifi hit . billion copyright lawsuit reuter min ago c reuter christian hartmann file photo headphon seen front logo onlin music stream servic spotifi illustr pictur music stream compani spotifi su wixen music publish inc last week alleg use thousand song includ tom petti neil young door without licens compens music publisher. popular search appl inc aapl . . . amazon.com inc amzn . . . walt disney co dis . . . inc v . . . wixen exclus license song free fallin tom petti light fire door girl got good thing weezer work singer stevi nick seek damag worth least . billion along injunct relief. spotifi fail get direct compulsori licens wixen would allow reproduc distribut song wixen said lawsuit file california feder court. wixen also alleg spotifi outsourc work third parti licens royalti servic provid harri fox agenc ill equip obtain necessari mechan licens . spotifi declin comment. may stockholm sweden base compani agre pay million settl propos class action alleg fail pay royalti song make avail users. spotifi plan stock market list year grown around percent valu least billion past months. report sonam rai eric auchard bengaluru edit maju samuel go msn home\n",
            "\tLabel: 1\n",
            "ciara linnan tomi kilgor marketwatch boe share enjoy gain vener blue chip ge languish faang stock facebook inc. appl inc. amazon.com inc. netflix inc. googl parent alphabet inc. generat lot buzz year take seat coach class biggest gainer dow jone industri averag year outperform lot even though silicon valley darl old economi compani origin date back . boe co. ba commerci airlin maker defens contractor enjoy . surg stock price leav next biggest gainer fellow old economi compani caterpillar inc. cat dust mere . gain. despit struggl late http www.marketwatch.com stori appl apolog admit slow iphon slash cost batteri replac appl aapl took fourth place . gain visa inc. v bare surpass last trade day year. two follow wal mart store inc. wmt mcdonald corp. mcd home depot inc. hd climb . faang stock manag gain certain exact shabby. amazon amzn gain year facebook fb tack . netflix nflx rose . alphabet googl googl ad . . two class stock. overal dow index rose . p gain . read biggest p winner loser tech health care home builder lead http www.marketwatch.com stori biggest sp winner loser tech health care home builder lead also biggest nasdaq winner loser chip maker videogam publish lead tech http www.marketwatch.com stori biggest nasdaq winner loser chip maker videogam publish lead tech chart show boe stock climb consist year notch seri record buoy better expect earn includ second quarter report impress investor sent stock almost singl session. boe top consensus expect sixth consecut quarter http www.marketwatch.com stori boe boost outlook despit tanker problem report third quarter earn octob deliv record commerci airliners. backlog stood aircraft end septemb equal six year deliveries. compani rais full year guidanc decemb announc new sharehold friend action http www.marketwatch.com stori boe increas dividend share repurchas plan share gain includ higher dividend stock buyback program valu billion. read share buyback machin overdr drop strong hint ceo plan tax save http www.marketwatch.com stori share buyback spike drop strong hint ceo plan tax save boe benefit current upsw aircraft demand driven increas air passeng demand asia discount carrier busi increas capacity. compani also boost cost cut measur http www.marketwatch.com stori boe worker take buyout introduc chief execut denni muilenburg prop margins. compani high hope new global servic divis includ crucial aftermarket servic airlin custom expect generat billion revenu within five years. meanwhil increas militari spend rocki geopolit backdrop provid anoth boost tax bill presid donald trump sign law dec. http www.marketwatch.com stori trump today presid say corpor go wild sign tax bill law . trump antitrad rhetor campaign earli day presid rais concern boe threat shutter export import bank http www.marketwatch.com stori boe find altern export import bank lender boe custom sometim call boe bank. miss compani make dow industri think tax cut http www.marketwatch.com stori here compani make dow industri think tax bill trump sinc revers stanc polici even visit compani south carolina plant februari celebr jobs. boe takeov talk brazilian aircraft maker embraer sa embr .br largest maker region jet move would boost competit edg rival airbus recent announc similar deal buy major stake jetlin program run canada bombardi bbd.a.t wall street journal report http www.marketwatch.com stori boe takeov talk brazilian rival embraer . ten best perform dow jone industri averag ticker co. name gain ba boe co. . cat caterpillar inc. . v visa inc. . aapl appl inc. . wmt wal mart store inc. . mcd mcdonald corp. . hd home depot inc. . unh unitedhealth group inc. us unh . msft microsoft corp. us msft . axp american express co. us axp . sourc marketwatch factset end spectrum anoth old economi compani general electr co. ge end annus horribili near tumbl octob alon mark worst one month selloff sinc depth great recession. investor appear unimpress new ceo john flanneri turnaround plan unveil novemb http www.marketwatch.com stori ges stock fall year low new sec rule cut profit estim billion send stock anoth . ge stock alreadi downtrend aug. compani announc sudden departur chief execut jeffri immelt https www.wsj.com articl ge ceo jeff immelt step year run top. immelt work reshap compani wake financi crisi jettison financi arm refocus core industri busi lines. immelt fought aggress make compani digit hire hundr softwar engin move compani headquart massachusett connecticut closer talent emerg state high regard universities. compani stock fail respond strateg move worst dow perform tenure. also ge credit downgrad moodi sever deterior financ http www.marketwatch.com stori ge credit downgrad moodi sever deterior financ flanneri place stock perform center transform plan includ shrink compani portfolio busi focus cash genera\n",
            "\tLabel: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_rPlQmp1erO",
        "outputId": "b6749bb3-e886-4890-acb9-f4d377e2fb65"
      },
      "source": [
        "print(pd.Series(dataset['train']['direction']).value_counts())"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    1231\n",
            "0     801\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UetFd0Dh1lUm"
      },
      "source": [
        "inputs, labels = np.array(dataset['train']['news']).reshape(-1,1), np.array(dataset['train']['direction'])"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOJFZMgq23-R",
        "outputId": "c39bfabd-ad62-4905-cf0a-82caacf64625"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import numpy as np\n",
        "\n",
        "n=100 # Number of instances for each class for test/validation sets\n",
        "\n",
        "# Define a random undersample that will give equal amounts of data for each label randomly\n",
        "rus = RandomUnderSampler(sampling_strategy={0:n, 1:n}, random_state=random_seed)\n",
        "rus.fit_resample(inputs, labels)\n",
        "\n",
        "# Get test indices from the random undersampler\n",
        "test_inds = rus.sample_indices_\n",
        "test_x, test_y = inputs[test_inds], np.array(labels)[test_inds]\n",
        "print(\"Test statistics\")\n",
        "print(pd.Series(test_y).value_counts())\n",
        "\n",
        "# Get rest (train + valid)\n",
        "rest_inds = [i for i in range(inputs.shape[0]) if i not in test_inds]\n",
        "rest_x, rest_y = inputs[rest_inds], labels[rest_inds]\n",
        "\n",
        "# Get valid indices from the random undersampler\n",
        "rus.fit_resample(rest_x, rest_y)\n",
        "valid_inds = rus.sample_indices_\n",
        "valid_x, valid_y = rest_x[valid_inds], rest_y[valid_inds]\n",
        "print(\"Valid statistics\")\n",
        "print(pd.Series(valid_y).value_counts())\n",
        "\n",
        "# Rest goes in training\n",
        "train_inds = [i for i in range(rest_x.shape[0]) if i not in valid_inds]\n",
        "train_x, train_y = rest_x[train_inds], rest_y[train_inds]\n",
        "print(\"Train statistics\")\n",
        "print(pd.Series(train_y).value_counts())"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test statistics\n",
            "1    100\n",
            "0    100\n",
            "dtype: int64\n",
            "Valid statistics\n",
            "1    100\n",
            "0    100\n",
            "dtype: int64\n",
            "Train statistics\n",
            "1    1031\n",
            "0     601\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aSF8sfn3FrV",
        "outputId": "b019c23a-ad58-4cf7-f350-a7c0f4770c6b"
      },
      "source": [
        "test_x[:10,0].tolist()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['las vega music legend lionel richi unlik pitchman newfangl medic devic sprawl consum electron show las vega week. eclect field health care technolog morph mani shape form commerci ventur explor possibl artifici intellig robot vast amount data. getti imag smartphon app small devic life size robot ces saw fair share technolog solutions. tech reshap larg swath multibillion dollar industri like manifest wearabl robot sensor ai conclud panel topic call invis doctor. anoth wild card amazon.com ticker amzn anticip entri pharmaci market. growth project health care tech market plenti make hard put definit figur expert agre enorm market. recent avail inform market research euromonitor intern peg global sale consum health product billion . everybodi come health care slosh money probabl trillion dollar say girish venkatachaliah former ibm watson health execut vice presid machin learn athenahealth athn . appl aapl alphabet googl googl amazon ibm ibm circl industry. amplifi come months. rub modifi revis health care hard. obstacl form fragment health care industri also heavili regul formid say venkatachaliah. ces crude glorifi lab health care industri may look like year medic profession attempt get handl grow mountain data digit age. perhap might even narrow grand divid tech savvi consum analog driven doctor dentist optometrist go say shoshana ungerleid doctor san francisco advis medic tech startups. super bullish medic technolog exist doctor offic hous sever year away counter adrian aoun former alphabet execut co found forward design state art medic facil u.s. combin sever examin room equip interact display two bodi scanner collect data via wearabl sensors. health care solut aliv well ces multipl form apps. richi academi award grammi win songwrit tout heal demand hous call app team qualcomm qcom someth call heal wellb . devic look like plug light wireless connect health care sensor log vital sign puls blood pressur heart rate. richi vega week recent phone interview said investor heal big believ technolog bring effici antiqu health care field. far heal deliv hous call nationwid less three years. natur extens primari call servic say heal ceo nick desai . also underscor say health care forefront technolog chang lives. meanwhil concierg key health earli stage build uber like health servic nationwid app let consum schedul appoint demand top tier physician general practition orthoped cardiolog special fields. far patient dozen citi includ new york los angel abil digit book appoint pool specialist urgent care hospit concierg clinics. newport beach calif. base startup join telehealth firm cure other develop app design match patient physician time healthcar industri wrestl primari care shortage. hardwar side come french compani cutti life size autonom robot companion seniors. mount touchscreen equip facial speech recognit technolog cutti intend connect senior friend famili healthcar providers. also take via screen activ yoga class museum visit cook lessons. devices. bowhead health develop ecosystem shape squat cylindr box hous home health test blockchain base health data manag system. mira fertil demonstr person ovul system leverag ai help coupl conceive. cocoon cam introduc clariti cocoon cam advanc babi monitor site www.cocooncam.com clarity. reliefband watch like contrapt offer drug free solut nausea associ motion sick vr activ chemotherapi pregnancy. final phonesoap disinfect doubl wireless charger display health well marketplace. guarante avoid ces flu market materi breathless promised. ces.',\n",
              " 'jia cang de ge gu pxd foxa fox cah mck agn abc qrvo amc vrtv jian cang de ge gu pbf imo fwp esrx berkshir hathaway jia cang de ge gu aapl bk mon usb jian cang de ge gu ibm gm sni aal wfc blue harbor xin jin de ge gu zayo mic logm axta tui chu de ge gu ffiv agco dnb laz jia cang de ge gu md comm otex fce adnt iwm ths jian cang de ge gu clns mdrx xlnx spi wcc bridgewat associ xin jin de ge gu pcg cvs cah ppl eix cmg orcl pg lli ipg tui chu de ge gu kr dva bwa biib intc viab ilmn tsn ntap txn jia cang de ge gu wba celg mu cost hyg lulu gld tlt jian cang de ge gu esrx dgx disca ge kor clinton group xin jin de ge gu mon ppl bco tsn cck lli hds celg frc pypl tui chu de ge gu dgx tpr ccl bpop prah aet ptla pep cbrl cotv jia cang de ge gu bio eix amgn eme wso tup moh lvs hsi vrtx jian cang de ge gu mcd ci ba fl bax cat fizz ago hum cc coatu manag xin jin de ge gu msft vmw ntes chtr qd tui chu de ge gu symc amt crm data twlo jia cang de ge gu twtr shop avgo amzn snap jian cang de ge gu aapl fb baba atvi ea corvex manag xin jin de ge gu twx chtr baba nxpi tui chu de ge gu ctl p pagp sig jia cang de ge gu cmcsa jblu fg fb tmus jian cang de ge gu evhc nomd googl egn duquesn famili offic xin jin de ge gu eog wfc bac dvn apa stmp cxo cog twx x tui chu de ge gu pcln baba ea c exp atvi lvs ibb cb celg jia cang de ge gu nktr msft amzn googl crm biib wday jian cang de ge gu ctrp jd pypl vale fb elliott manag xin jin de ge gu md akam unit cvg qep tdw wit tui chu de ge gu eca mpc adnt ryaay wyn mon acad eqt gra abg jia cang de ge gu tco egn hes isbc jian cang de ge gu aa nrg mitl gpi impv sah emin capit xin jin de ge gu elli mgm mdlz pypl pzza ea len b tui chu de ge gu exp beri stz kar fce rxn cnne mat nke jia cang de ge gu iqv usfd efx wen cybr gpi p jian cang de ge gu arr antm jack impv cbg lq spgi mstr ice znga engag capit tui chu de ge gu thc fnsr dbd dxcm xper jia cang de ge gu cls ncr iwm bhe jian cang de ge gu med ccrn xin jin de ge gu dnli optn abeo rytm ablx tui chu de ge gu nvro lli nxtm axdx spa jia cang de ge gu unh bdx abbv sage nktr jian cang de ge gu amgn mdt bsx celg agn glenview capit xin jin de ge gu nwl agn chtr dlph mik armk cah lyb tui chu de ge gu zbh nke twtr wyn mgm px jia cang de ge gu wba cvs uh mck fdc wp tmo fdx ebay wmb jian cang de ge gu abbv low aapl hca aet dnb googl dwdp ci mtor greenlight capit xin jin de ge gu ceix twtr twx esv mdco jcp kss bbi w sfli tui chu de ge gu gdx hpe tsg mon tgna rad uhal car fred tecd jia cang de ge gu bhf jian cang de ge gu gm aer tpx cnx mu dds cndt cc dsw highfield capit manag xin jin de ge gu cmcsa amzn axta exp axp mdlz ge cern tco chtr tui chu de ge gu tgt ko sum fe egn jia cang de ge gu twx teva hca shpg mon cce pe kr h nvda jian cang de ge gu fdx bhge ben mar hds ctsh mik ivz cve amt icahn associ',\n",
              " 'faang stock could hold netflix updat nov. p.m. et order reprint text size mayb good thing netflix nflx faang stock. think imperi capit analyst david miller whose price target among highest wall street accord factset friday reiter outperform rate bump estim upward project subscrib growth. netflix stock . friday trade quarter. despit impress earn releas oct. netflix round beat everi relev consensus metric guidanc stock essenti back mid april miller wrote. reason either poor market psycholog surround rest faang shorthand facebook fb appl aapl amazon.com amzn netflix googl parent alphabet googl third quarter financi result rest faang came short expectations. newslett sign issu faang stock miller suggest noth netflix. would advis investor ignor nois around faang instead focus core fundament netflix quit healthy. wall street exact bearish netflix. factset averag price target stock around suggest upside. mkm partner rob sanderson friday rais price target netflix say strongest compani media forecast peak net custom addit . also rais target amazon factset average. believ secular forc competit advantag much intact amazon expect share migrat continu well next decad wrote. recommend read',\n",
              " 'nigam arora want edg invest need look money flow smart money momo crowd investor want edg stock market know experi segment money flow one tool work. rip roar bull market mani investor care edge. simpli believ buy buy buy. investor realiz want tool give better foresight. foresight better hindsight let us explor segment money flow help chart. read stock market overreact fear economi overblown http www.marketwatch.com stori stock market overreact fear economi overblown chart pleas click https thearorareport.com chart money flow popular tech stock chart show segment money flow popular tech stocks. sinc tech stock leader market make sens look tech stock addit dow jone industri averag popular broad etf p etf spi nasdaq qqq small cap etf iwm . pleas note follow nvidia nvda poster child bull market. nvidia trade smart money flow nvidia negat momo momentum crowd money flow posit time extrem positive. sinc smart money flow consist stay negat nvidia momo crowd money flow stay posit stock gap down. nvidia recent trade low . . interest stay negat long time smart money flow turn neutral nvidia momo crowd money flow extrem negative. declin top nvidia arora report rate sell. howev zyx chang method come close give buy signal major spike nvidia recent low. provid specif buy zone along stop zone target zone appropri posit size signal given. appl aapl reach high . smart money flow neutral momo crowd money flow posit time extrem positive. drop appl stock momo crowd money flow appl negative. arora report buy rate appl drop top no. smart money flow posit intel intc neutral amd amd . momo crowd money flow negat both. smart money flow mild posit facebook fb googl googl googl . smart money flow neutral alibaba baba momo crowd money flow extrem negative. smart money flow neutral amazon amzn netflix nflx microsoft msft tesla tsla . ask arora nigam arora answer question invest stock etf bond gold silver oil currencies. question send nigam arora mailto ask arora thearorareport.com . rank chart also show relat rank popular tech stocks. rank base six screen zyx chang method. pleas click https thearorareport.com zyxmethod learn six screens. risk adjust rank use medium term long term positions. non risk adjust rank use short term posit trade around positions. investor need accept charact market changing. work past nine year may work future. investor ought shift mindset buy buy buy mode. consid follow comprehens adapt model proven track record bull bear markets. import reli static model market condit changed. disclosur subscrib arora report http thearorareport.com may posit secur mention articl may take posit time. nigam arora investor engin nuclear physicist background found two inc. fastest grow companies. founder arora report publish four newsletters. nigam reach nigam thearorareport.com mailto nigam thearorareport.com . nigam arora et',\n",
              " 'powerhous session earn report left major index mix stock fade afternoon trade investor look toward busi hour session. x struggl . gain exxon mobil xom walt disney dis post index top gains. nasdaq composit slump . paypal pypl tractor suppli tsco fell bottom nasdaq . p lost fraction. russel small cap gaug took . gain day. volum higher accord preliminari numbers. mix day data. downsid job cut rose sharpli januari labor depart estim sharp increas labor product cost fourth quarter. hand week jobless claim dip forecast increas institut suppli manag januari manufactur gaug decreas still came expectations. close quarter result come appl aapl amazon.com amzn alphabet googl among mani others. amazon rose alphabet fell extend trade follow reports. facebook fb roll gain nail new high analyst race lift stock price target follow posit fourth quarter report late wednesday. stock end near top buy rang . buy point. diversifi media compani meredith mdp collaps kill seven week base effort report general better expect fiscal second quarter results. compani also began offici move downtown manhattan offic time purchas . billion november. tumbl food ingredi heavyweight ingredion ingr sent grain industri group day worst perform among industries. ingredion report fourth quarter earn miss analyst forecast wide margin. declin sent share back . buy point stock week move average. tractor suppli tsco cave stab week move averag heavi trade. retail fourth quarter result narrowli clear expect midpoint full year revenu guidanc consensus target. share remain extend cup base stock clear november. alibaba group hold baba slice lower follow mix fiscal third quarter perform announc taken stake ant financi unit spun . slip sent alibaba back test cup base buy point . . among day big winner cimpress cmpr bolt follow quarter report. stock score breakout session includ ferrari race ezcorp ezpw opentext otex . chipmak qorvo qrvo swung boost fiscal third quarter result news land key suppli contract appl . share wrap session buy rang . buy point cup base. friday morn earn roster call report sever big oil name led chevron cvx exxon mobil. drugmak merck mrk astrazeneca azn also list. investor tune labor depart month payrol report due open. import market news thursday job big oil earn drive market friday invest action plan alibaba test buy point earn miss ant financi stake qorvo rocket appl contract win broadcom slip take two interact softwar gun wild west game delay look next nvidia start simpl routin',\n",
              " 'copi person non commerci use only. order present readi copi distribut colleagu client custom visit http www.djreprints.com. https www.barrons.com articl faang stock big ralli billion faang ad billion market valu today dec. p.m. et order reprint amazon ceo jeff bezo photograph alex wong getti imag text size wednesday one market best day decade. dow jone industri averag soar near point nasdaq composit . . infam faang stock facebook fb appl aapl amazon.com amzn netflix nflx googl parent alphabet googl set tempo. amazon finish whop . ad . billion market value. u.s. onlin spend holiday season rose last year bulk growth thank amazon. meanwhil bullish analyst report help appl stock shake recent doldrum today rise . gain . billion market value. faang group close watch domin technolog fast growth market lead gain much least bull market ralli ran steam fall. wednesday relief ralli alphabet valu rose . . billion facebook increas . . billion netflix climb . . billion. add togeth faang gang worth . billion even market opened. zoom bit pictur pretti . sinc peak group shed trillion dollar market value.',\n",
              " 'new york cnn busi earlier year tech stock fire . mani struggl prospect seem get better. tech rattl escal trade war unit state china. relat two countri could turn even sour chines tech giant huawei chief financi offic detain canada. meng wanzhou arrest request unit state sent shock wave global stock market last week . chines tech stock among hardest hit. meanwhil chines court ban sale import iphon models. practic effect injunct yet clear. rule announc public monday put effect last week. appl aapl said statement iphon model remain avail china. unit state fear rise interest rate slow growth spark exodus former tech darl like amazon amzn alphabet googl . read compani like facebook netflix econom fear pile onto exist problems. facebook fb lost near valu year tri fend crisi crisi . netflix nflx year stumbl sinc summer miss analyst expect . market stream live new york stock exchang everi wednesday p.m. et. expert warn investor away tech companies. charl schwab downgrad tech stock outperform neutral august. liz ann sonder chief invest strategist bank said see tech stock return leadership role near medium term. sonder join cnn busi correspond alison kosik discuss tech slump prefer sector market tuesday. market stream live new york stock exchang everi wednesday p.m. et. host cnn busi correspond minut program featur incis commentari experts. watch market cnn.com marketsnow desk phone tablet. catch show live check highlight onlin market newslett deliv inbox everi afternoon.',\n",
              " 'marc pinto watch portfolio manag marc pinto talk bloomberg tv opportun disrupt energi industri fang stocks. also discuss outlook growth. transcript scarlet fu want bring guest marc pinto. janus henderson portfolio manager. marc read technolog obvious fang stock gotten hammer today recov littl bit new york fang index instanc somewhat higher even appl nasdaq aapl amazon nasdaq amzn continu decline. see go forward argu massiv rate sector. other say growth bid much get revers mean. marc pinto yeah think look busi compani general well right lot discuss compani disrupt compani disrupted. clear stock fang index amazon great exampl disrupt increas amount industri touch. term valuat lot compani alphabet nasdaq goog nasdaq googl exampl valuat actual move much higher earn cash flow grown. valuat argu still reason growth outlook still good. think littl bit profit taking. stock done aw well think peopl go year end want protect gain extent them. think fundament chang lot busi models. disclaim although tri ensur transcript accur make provid enabl search treat true record spoken word. execut interview associ compani ei accept liabil said discrep spoken written word error omissions. doubt aris pleas refer origin broadcast video clip. make video clip avail neither ei right holder respect partner associ way endors view opinion express interviewe interviewe organ product activ services. read accept disclaimer. technolog industri signific affect obsolesc exist technolog short product cycl fall price profit competit new market entrant general econom conditions. concentr invest singl industri could volatil perform less concentr invest market whole. fang stock refer facebook nasdaq fb amazon netflix nasdaq nflx googl alphabet inc. janus henderson trademark janus henderson group plc one subsidiari entities. c janus henderson group plc. c pleas consid charg risk expens invest object care investing. pleas see prospectus avail summari prospectus contain information. read care invest send money. opinion view express date publish subject chang without notice. inform purpos use constru offer sell solicit offer buy recommend buy sell hold secur invest strategi market sector. forecast guaranteed. opinion exampl meant illustr broader theme indic trade intent. intend indic impli illustr exampl mention ever held portfolio. janus henderson group plc subsidiari may manag invest product financi interest secur mention herein comment constru reflect past futur profitability. guarante inform suppli accur complet time warranti regard result obtain use. past perform guarante futur results. invest involv risk includ possibl loss princip fluctuat value. janus henderson investor c . right reserved.',\n",
              " 'big stock chart tuesday mu wdc pypl read break news sponsor home stock pick stock buy reason consid buy amazon stock jan est januari reason consid buy amazon stock amazon stock worth look high http bit.li tjc oz share amazon nasdaq amzn definit solid ralli low mean investor miss chanc go long inde amazon stock low keep mind still almost highs. sourc shutterstock investor say mean alreadi miss bulk rebound investor consid take profit least stay sidelines. say go right right now. keep mind long ago investor would kill get . anoth chance. let look reason investor consid long amazon stock position. growth cours one top reason consid buy amazon growth. thank industri lead cloud busi amazon web servic compani robust top bottom line growth. compani report earn jan. . full year analyst expect earn per share . revenu . billion. achiev repres growth . respectively. estim call anoth earn growth sale growth. certain repres year year deceler growth rate although declin overal still pretti impress number compani long runaway ahead particular compani size billion. appl nasdaq aapl microsoft nasdaq msft alphabet nasdaq googl nasdaq goog attract valuat amazon stock never cheap earn basis. reason buy necessarili stock ten year return show hinder performance. amazon busi second reason consid own amazon stock compani vast moat. prime membership two day ship better cloud storag music huge generat cash flow. whole food acquisit profit entiti purchas allow amazon entri one retail biggest footprint grocery. onlin busi remain robust let honest e commerc go anywhere. bode well amazon short long term. final amazon advertis busi cloud comput busi offer plenti growth opportun next year beyond. give investor confid growth continu particular busi segment amazon brewing. trade amazon stock click enlarg final amazon stock chart third catalyst consid get long. mention share still well high share like way away get price opportunity. admit amzn sit notabl resist . addit stock technic trend lower. said share consolid nice day day move averages. decent support near even amzn stock overshot level december. mind investor look amzn stock justifi take small posit now. add stock decline. bret kenwel manag author futur blue chip twitter bretkenwel . write bret kenwel long aapl googl amzn. investorplace.com reason consid buy amazon stock simg .',\n",
              " 'shelagh dolan voic assist like amazon alexa googl assist appl siri microsoft cortana peg trigger widespread transform across retail industri year come. current interest adopt voic assist commerc driven recent technolog breakthrough advantag tech exist channel develop voic apps. consum demand voic technolog mount brand offer function throughout entir custom journey stand gain three key ways. long ago friend smart speaker like amazon alexa googl assist live room seem like rare novelty. within matter month howev smart speaker start becom household stapl still fraction growth potential. busi insid intellig one biggest driver adopt increas functionality. smart speaker chang music turn light help consum find new product make purchas quick becom prefer method shopping. fact near quarter consum global alreadi prefer use voic assist go compani websit mobil app shop. share jump accord capgemini. consum board prompt conveni natur shop smart speaker brand join stand reap massiv rewards. voic retail report busi insid intellig busi insid premium research servic highlight valu voic bring shop funnel retail implement throughout custom journey. three way brand captur consum voic technolog drive product purchas voic assist make spend faster easier consum unabl use hands. abil make purchas channel addit person intellig element shop experi simplifi transit product discoveri product purchase. heighten custom loyalti brand leverag voic assist post purchas phase track deliveri status autom part return process interact custom servic offer feedback collect consum behavior transact data. shift consum spend behavior smart devic ownership snowbal effect smart devic ecosystem reach mainstream consum flock connect car smart home devic applianc connect virtual realiti augment realiti vr ar headsets. want learn shopper interest use voic assist everi stage custom journey initi product search discoveri post purchas custom servic deliveri status. retail take advantag consum desir leverag voic stronger posit heighten custom engag increas convers time drive sale boost oper efficiency. voic retail report busi insid intellig examin trend drive adopt voic commerc detail role voic throughout custom shop journey outlin brand benefit implement voic strategi explor ahead technolog retail. follow us also check copyright c insid inc. right reserved. registr use site constitut accept']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC4fkJ-B3J5P"
      },
      "source": [
        "model_bert = {}\n",
        "tokenizer_bert = {}"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLzQ3voX31MM"
      },
      "source": [
        "\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "# Download FinBERT tokenizer\n",
        "# Before running the model below download the vocab file by following the instruction above\n",
        "tokenizer_bert['finbert'] = BertTokenizer.from_pretrained(os.path.join('data', 'fin_vocab'))"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9CgctnV5C9I",
        "outputId": "cb830be6-702b-4160-ee22-8adcad094adc"
      },
      "source": [
        "text = \"401(k) Asset Turnover Ratio Blockchain Bankruptcy Demonetization FAANG Stocks Fintech Home Equity Loan Indemnity Insurance Liquidity Macroeconomics\"\n",
        "\n",
        "\n",
        "# Output of FinBERT\n",
        "encoded_ids = tokenizer_bert['finbert'](text, return_tensors='tf')\n",
        "encoded_tokens = tokenizer_bert['finbert'].convert_ids_to_tokens(encoded_ids['input_ids'].numpy()[0])\n",
        "print('FinBERT says ...\\n')\n",
        "print(encoded_tokens)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FinBERT says ...\n",
            "\n",
            "['[CLS]', '401', '(', 'k', ')', 'asset', 'turnover', 'ratio', 'block', '##chain', 'bankruptcy', 'demo', '##net', '##ization', 'faa', '##ng', 'stocks', 'fin', '##tech', 'home', 'equity', 'loan', 'indemnity', 'insurance', 'liquidity', 'macroeconomic', '##s', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z3u7UoS-j2b",
        "outputId": "4c31675c-ae10-415b-dccd-3e2b0622d687"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "# Let's now create BERT + classifier model to solve the usecase\n",
        "num_labels = 2\n",
        "model_bert['finbert+classifier'] = TFBertForSequenceClassification.from_pretrained(os.path.join('models','finbert'), num_labels=num_labels, from_pt=True)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQG0Q_MA-pLD",
        "outputId": "7ecfa38c-7dff-4ab3-92e0-2b084bbe36d2"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model_bert['finbert+classifier'].compile(optimizer=optimizer, loss=loss, metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "model_bert['finbert+classifier'].summary()"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109751808 \n",
            "_________________________________________________________________\n",
            "dropout_455 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 109,753,346\n",
            "Trainable params: 109,753,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO51YRPE-x00",
        "outputId": "439c8a74-e13d-4834-c77b-006c21c46562"
      },
      "source": [
        "seq_length = []\n",
        "\n",
        "remove_list_train = []\n",
        "for indx, val in np.ndenumerate(train_x):\n",
        "  if val == None:\n",
        "    print(\"yooooooooo\")\n",
        "    print(val)\n",
        "    remove_list_train.append(indx)\n",
        "\n",
        "    \n",
        "new_train_x = np.delete(train_x, remove_list_train)\n",
        "new_train_y = np.delete(train_y, remove_list_train)\n",
        "\n",
        "remove_list_valid = []\n",
        "for indx, val in np.ndenumerate(valid_x):\n",
        "  if val == None:\n",
        "    print(\"yooooooooo\")\n",
        "    print(val)\n",
        "    remove_list_valid.append(indx)\n",
        "\n",
        "new_valid_x = np.delete(valid_x, remove_list_valid)\n",
        "new_valid_y = np.delete(valid_y, remove_list_valid)\n",
        "\n",
        "\n",
        "for x in new_train_x:\n",
        "    # print(type(x))\n",
        "    # print(x)\n",
        "    seq_length.append(len(tokenizer_bert['finbert'](x[0])['input_ids']))\n",
        "\n",
        "train_x = new_train_x\n",
        "print(len(train_x))\n",
        "print(len(train_y))\n",
        "train_y = new_train_y\n",
        "print(len(train_y))\n",
        "\n",
        "valid_x = new_valid_x\n",
        "valid_y = new_valid_y\n",
        "\n",
        "print(pd.Series(seq_length).describe(percentiles=[0.25,0.5,0.75,0.9]))\n",
        "print(pd.Series(seq_length).median())"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1632\n",
            "1632\n",
            "1632\n",
            "count    1632.0\n",
            "mean        3.0\n",
            "std         0.0\n",
            "min         3.0\n",
            "25%         3.0\n",
            "50%         3.0\n",
            "75%         3.0\n",
            "90%         3.0\n",
            "max         3.0\n",
            "dtype: float64\n",
            "3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahhrXiyBIgdb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb-0HPj6_M0T",
        "outputId": "f3ab295d-6524-42e3-d7bc-492adba2ac85"
      },
      "source": [
        "def examples_to_features(x, tokenizer):\n",
        "    \"\"\" Convert an example to a dictionary BERT model accepts \"\"\"\n",
        "    res = tokenizer(x, padding=True, truncation=True, max_length=50, return_tensors='tf')\n",
        "    return dict(list(res.items()))\n",
        "\n",
        "\n",
        "a = train_x.reshape(-1).tolist()\n",
        "print(type(a))\n",
        "print(type(a[0]))\n",
        "print(a[0])\n",
        "train_tokens = examples_to_features(train_x.reshape(-1).tolist(), tokenizer_bert['finbert'])\n",
        "train_labels = train_y.reshape(-1,1)\n",
        "\n",
        "valid_tokens = examples_to_features(valid_x.reshape(-1).tolist(), tokenizer_bert['finbert'])\n",
        "valid_labels = valid_y.reshape(-1,1)\n",
        "\n",
        "\n",
        "# Sample data\n",
        "sample_text = \"Company shares are down\"\n",
        "# sample_text = \n",
        "print(examples_to_features(sample_text, tokenizer_bert[\"finbert\"]))"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'str'>\n",
            "andr januari nasdaq surg big name tech stock continu show dominance. well fang stock perform could room run scorecard facebook fb amazon amzn netflix nflx googl parent alphabet googl appl aapl . facebook x facebook gain . stock last broke base octob seen somewhat sluggish sideway action sinc then. facebook share remain within buy rang . entri lost support key day line. facebook also new flat base . buy point. investor may want focus entri now. amazon amazon share increas stock could soon present fresh buy opportunity. friday close stock complet five week base build minimum amount time take base form. new buy point . . late stage base mean higher odd failing. ibd take look high qualiti stock potenti big gain make sure check leaderboard curat list top growth name near potenti buy points. new ibd take free trial leaderboard. netflix netflix rose year built sever base along run. share close friday back day line tri build right side base . entry. alphabet googl parent alphabet climb least fang peer year. hit time high . dec. share steadili slip push stock back buy range. last entri point alphabet . . appl appl gain year. appl recent breakout . flat base buy point met resist share lost support day line friday. declin could trigger sell signal convinc support day line would posit indicator. might interest stock buy watch top ipo big small cap growth stock dow jone industri averag dow stock news analysi fang stock news quot facebook amazon netflix googl\n",
            "{'input_ids': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[  3,  37, 203,  21, 269,   4]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1]], dtype=int32)>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkn9f7PsI3o_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQYT9T2e_qRN",
        "outputId": "4d4e5c99-8e4a-4fa5-c5e4-430eb2ad3b97"
      },
      "source": [
        "def get_class_weights(labels):\n",
        "    \"\"\" Get class weights for classes. Less data more weight \"\"\"\n",
        "    n_freq = pd.Series(labels.reshape(-1)).value_counts()\n",
        "    dct = {}\n",
        "    for lbl in [0,1]:\n",
        "        if lbl==0:\n",
        "            others = [1]\n",
        "        elif lbl==1:\n",
        "            others = [0]\n",
        "        dct[lbl] = n_freq[others].sum()/n_freq.sum()\n",
        "    return dct\n",
        "\n",
        "print(get_class_weights(train_labels))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.6317401960784313, 1: 0.36825980392156865}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5-ze_wHCvfl",
        "outputId": "c20f9639-343b-4b47-bac5-9a35fba093dc"
      },
      "source": [
        "# Finetune FinBert on the financial sentiment classification task\n",
        "import time\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "model_bert['finbert+classifier'].fit(\n",
        "    train_tokens, train_labels, \n",
        "    validation_data=(valid_tokens, valid_labels), \n",
        "    class_weight=get_class_weights(train_labels),\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "t2 = time.time()\n",
        "print(\"It took {} seconds to complete the training\".format(t2-t1))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "51/51 [==============================] - ETA: 0s - loss: 0.3232 - sparse_categorical_accuracy: 0.5417WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "51/51 [==============================] - 30s 388ms/step - loss: 0.3233 - sparse_categorical_accuracy: 0.5413 - val_loss: 0.7155 - val_sparse_categorical_accuracy: 0.5250\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 17s 331ms/step - loss: 0.2893 - sparse_categorical_accuracy: 0.6223 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6550\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 17s 326ms/step - loss: 0.1813 - sparse_categorical_accuracy: 0.8231 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.6750\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 16s 323ms/step - loss: 0.0791 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.7515 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 16s 322ms/step - loss: 0.0684 - sparse_categorical_accuracy: 0.9577 - val_loss: 0.9220 - val_sparse_categorical_accuracy: 0.7050\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 17s 325ms/step - loss: 0.0367 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.9982 - val_sparse_categorical_accuracy: 0.7100\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 17s 326ms/step - loss: 0.0363 - sparse_categorical_accuracy: 0.9771 - val_loss: 1.1087 - val_sparse_categorical_accuracy: 0.6800\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 17s 327ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9727 - val_loss: 1.5213 - val_sparse_categorical_accuracy: 0.6800\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 17s 325ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9740 - val_loss: 1.2980 - val_sparse_categorical_accuracy: 0.7100\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 17s 324ms/step - loss: 0.0159 - sparse_categorical_accuracy: 0.9844 - val_loss: 1.4030 - val_sparse_categorical_accuracy: 0.7050\n",
            "It took 178.9480504989624 seconds to complete the training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCOBG8__1LYm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD7i4gPCIh_B",
        "outputId": "2bdc2689-f7e0-4860-b530-165c1ac9ea1f"
      },
      "source": [
        "if not os.path.exists(os.path.join('models', 'finbert_classifier')):\n",
        "    os.makedirs(os.path.join('models', 'finbert_classifier'))\n",
        "if not os.path.exists(os.path.join('tokenizers', 'finbert_classifier')):\n",
        "    os.makedirs(os.path.join('tokenizers', 'finbert_classifier'))\n",
        "\n",
        "# Save the modle\n",
        "model_bert['finbert+classifier'].save_pretrained(os.path.join('models', 'finbert_classifier'))\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer_bert['finbert'].save_pretrained(os.path.join('tokenizers', 'finbert_classifier'))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizers/finbert_classifier/tokenizer_config.json',\n",
              " 'tokenizers/finbert_classifier/special_tokens_map.json',\n",
              " 'tokenizers/finbert_classifier/vocab.txt',\n",
              " 'tokenizers/finbert_classifier/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nDR9myGI5Mk",
        "outputId": "3c4766ab-457f-4b04-db64-aac1550f30c0"
      },
      "source": [
        "# Load the model\n",
        "model_bert['finbert+classifier'] = TFBertForSequenceClassification.from_pretrained(\n",
        "    os.path.join('models','finbert_classifier'), num_labels=num_labels)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer_bert['finbert'] = BertTokenizer.from_pretrained(os.path.join('tokenizers', 'finbert_classifier'))\n",
        "\n",
        "# Compile the model so it can be used for predictions\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model_bert['finbert+classifier'].compile(optimizer=optimizer, loss=loss, metrics=tf.keras.metrics.SparseCategoricalAccuracy())"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at models/finbert_classifier were not used when initializing TFBertForSequenceClassification: ['dropout_455']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at models/finbert_classifier.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJlA7Y2QJOt_",
        "outputId": "d6796b1c-d77c-4cc2-b69d-20ee169cf547"
      },
      "source": [
        "\n",
        "a = test_x.reshape(-1).tolist()\n",
        "b = test_y.reshape(-1,1)\n",
        "print(type(a))\n",
        "b_list = []\n",
        "if type(a[0]) == str:\n",
        "  print(\"HIIIII\")\n",
        "for indx, val in enumerate(a):\n",
        "  if type(val) != str:\n",
        "    print(\"yooooooooo\")\n",
        "    a.pop(indx)\n",
        "    b_list.append(indx)\n",
        "    \n",
        "new_b = np.delete(b, b_list)\n",
        "\n",
        "    \n",
        "# print(a[0])\n",
        "test_tokens = examples_to_features(a, tokenizer_bert['finbert'])\n",
        "test_labels = new_b\n",
        "\n",
        "model_bert['finbert+classifier'].evaluate(test_tokens, test_labels)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "HIIIII\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "7/7 [==============================] - 3s 101ms/step - loss: 1.6014 - sparse_categorical_accuracy: 0.6950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3053195476531982, 0.7300000190734863]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    }
  ]
}